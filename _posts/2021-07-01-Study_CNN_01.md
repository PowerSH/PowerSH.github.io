---
layout: archive
title: "[CNN]Image Classification"
categories: categories/ML
---

<!-- Cat vs Dog, Data Augmentation, Adversarial Attack -->

# [CNN]Image Classification - #1
머신러닝은 대표적으로 지도학습(`Supervised Learning`), 비지도학습(`Unsupervised Learning`), 강화학습(`Reinforcement Learning`)으로 나눌 수 있습니다. 이 중에서 우리가 진행 할 이미지 분류 문제는 지도학습에 해당합니다. 지도학습이란 데이터와 레이블을 입력으로 하여 컴퓨터가 학습하고 데이터(`Data`)와 레이블(`Label`)간의 관계를 일반화시킨 상태에서 새로운 데이터로 하여금 성능을 검증받는 것을 의미합니다.

![machine-learning_tree](https://user-images.githubusercontent.com/39876295/123266015-9504c480-d536-11eb-97c6-25eb5add3fca.png)

<center>

[이미지 출처 : [Abdul Rahid](https://www.slideshare.net/awahid/big-data-and-machine-learning-for-businesses)]
</center>

지도학습에서 다루는 문제들을 크게 두 가지로 분류할 수 있습니다. 바로 분류문제(Classification)와 회귀문제(Regression)입니다. 분류문제는 몇 가지 그룹으로 라벨링 된 집합을 특정 기준으로 나누는 것을 의미합니다. 라벨링 된 그룹이 두 가지 뿐이라면 이진 분류(Binary Classification)라고 불립니다.

이번 포스팅에서는 강아지와 고양이 이미지를 활용하여 이진 분류를 진행합니다. 강아지라는 레이블과 고양이라는 레이블로 나뉜 두 가지 그룹을 머신러닝을 활용해서 분류합니다. 이미지가 사용되는 분야에서 널리 활용되는 인공 신경망인 CNN(Convolution Neural Network)를 활용하는데 자세한 내용은 이후 포스팅에서 다루도록 하겠습니다.

본론으로 들어가기에 앞서 머신러닝은 전체적으로 비슷한 구도를 가지고 있습니다. 빠른 이해를 위해 최대한 간략하게 카테고리화 하여 설명하자면 아래와 같습니다.

**데이터 전처리** -> **모델 구성** -> **모델 학습** -> **모델 검증**

우리의 목표는 최종적으로 좋은 성능의 모델을 얻는 것이며, 좋은 성능이란 모델을 개발하는 사람이 추구하는 방향에 맞게 `예측`하는 것을 일컫습니다. 하지만 모델의 구조를 잘 만든다하여도 데이터가 좋지 않다면 성능은 당연히 떨어질 수 밖에 없습니다. 데이터 전처리는 모델이 잘 학습할 수 있도록 데이터를 정제하는 과정이라고 이해하시면 되겠습니다. 이제 본론으로 넘어가도록 하겠습니다.

*본 포스팅은 Google Colaboratory에서 실습되었습니다.*

<!-- 가끔 403 forbidden이 뜨면 kaggle에서 대회에 참여하지 않아서 그런 것이다. -->

## 데이터 준비
데이터 셋은 [Kaggle](https://www.kaggle.com/shaunthesheep/microsoft-catsvsdogs-dataset)에서 받을 수 있습니다. Kaggle에 가입하시고 API key를 다운받아서 Google Colab에서 바로 데이터를 사용할 수도 있습니다. 추가 포스팅 되는대로 링크를 업로드 해두겠습니다.

```python
!pip install kaggle
```
kaggle 데이터 셋을 사용하기 위해 관련 라이브러리를 설치합니다. <br>
**`!`는 `Jupyter Notebook` 환경에서 터미널에서와 같은 처리를 요청할 때 사용합니다.**
<br>
```python
from google.colab import files
files.upload()
```
Google Colab에서 파일 시스템 입출력을 지원하는 라이브러리를 `import` 합니다. `files.upload()`로 현재 실행되고 있는 세션에 사용자 컴퓨터에 있는 파일을 업로드 할 수 있습니다. 업로드 된 파일은 세션이 열려있는 경우에만 유지되며, 세션이 종료되면 이전에 업로드한 파일은 제거됩니다.<br>
업로드할 파일을 얻기 위해서 우선 Kaggle에 회원가입을 해야합니다. Google계정과 연동할 수 있어서 쉽게 진행할 수 있습니다. 만약 이미 회원가입이 되어있다면 `[My Account]` 에서 API key를 다운로드하면 됩니다. 파일명은 `kaggle.json`이며 해당 파일을 업로드 해주시면 됩니다.
<br>

```python
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json
```
업로드한 `kaggle.json`파일을 `~/.kaggle`이라는 디렉토리를 만들어서 해당 디렉토리에 복사해줍니다. `chmod(Change Mode)`를 사용해서 `~/.kaggle/`디렉토리의 `kaggle.json`을 활성화 시켜줍니다. `600`이란 숫자가 의미하는 바는 리눅스 명령어 포스팅에서 자세히 다루도록 하겠습니다.
<br>

```python
!kaggle datasets download -d tongpython/cat-and-dog
```
이제 `Kaggle`에서 데이터를 가져올 수 있는 API key도 얻었으니 데이터셋을 받아오겠습니다.
<br>

```python
!unzip cat-and-dog.zip
```
받아온 데이터는 홈 디렉토리에 위치하게 되며 별도의 경로 변경 없이 해당 위치에서 압축을 풀어줍니다. 압축이 풀어진 이후엔 디렉토리 구조가 아래 이미지처럼 나오게 됩니다.
<center>

![image](https://user-images.githubusercontent.com/39876295/123631671-fa67f680-d851-11eb-9d27-d8a4f14c0c67.png)

[cat-and-dog 디렉토리 트리]

</center>

<br>
```python
import os
import numpy as np
import tensorflow as tf

SIZE = 64
BATCH = 32
EPOCHS = 10

data_dir = os.path.join(os.getcwd(), 'training_set/training_set')
```
이제 데이터 준비는 완료되었습니다. 파이썬 코드 내에서 사용할 수 있도록 `data_dir` 변수에 담아주도록 합니다.<br>
`SIZE`, `BATCH`, `EPOCHS`는 추후 인공신경망을 구성하는 요소들을 미리 정의해놓은 것 입니다. 각 변수들의 의미는 이후 코드를 설명하면서 알아보도록 하겠습니다.
<br>

## 데이터 증폭
```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator
imageGenerator = ImageDataGenerator(
    rescale=1./255,
    validation_split=.2
)
```
**Tensorflow 1.2**에서부터 **Keras**가 `tensorflow.keras`와 같은 형태로 사용이 가능합니다. 편의상 `Tensorflow`와 `Keras`를 독립적으로 지칭하겠습니다. <br>
`Keras`에서 `ImageDataGenerator`를 제공해줍니다. `ImageDataGenerator`는 데이터 증폭이라고 불리는 `Data Augmentation` 기능을 여러가지 제공해줍니다. 사용하려는 데이터에 여기에서 정의한 내용을 적용해서 인공신경망 학습의 입력으로 제공합니다. 현재 코드에선 `rescale=1./255`와 `validation_split=.2`만을 적용한 상태입니다. 먼저 `validation_split=.2`는 `Validation Set` 즉, 검증 세트를 전체 데이터의 **20%**로 적용한다는 의미입니다. <br>
그리고 `rescale=1./255`를 설명하기에 앞서 이미지를 구성하려면 데이터가 어떻게 구성되어야 하는지와 인공신경망이 학습을 하기 위해서는 어떤 데이터 형태가 요구되는지를 이해할 필요가 있습니다.<br>
먼저 이미지는 0~255의 RGB값으로 구성되어 있습니다. 그렇다면 이미지의 한 픽셀에는 총 3개의 값이 필요합니다. 예를 들어 빨간색 픽셀을 표현하기 위해서 (R, G, B)라면 (255, 0, 0)라고 표현이 됩니다. 이걸 **`채널(Channel)`** 이라고 부릅니다.<br>
색이 표현되는 이미지는 3채널 이미지이며, 회색으로만 표현되는 이미지는 1채널 이미지 또는 `Grey Scale`이라고 부릅니다.<br>
보통의 `learning rate`를 사용하는 인공신경망은 흑백인 `Grey Scale`이미지로 학습합니다. 이유는 `3채널 (RGB)`의 이미지로 학습하게 되면 학습 시간이 비약적으로 상승하며 `Grey Scale`을 적용한 이미지를 사용하는 것에 비해 효율적이지 않습니다.
<br>

```python
X_train = imageGenerator.flow_from_directory(
    data_dir,
    target_size=(SIZE, SIZE),
    subset='training'
)

X_valid = imageGenerator.flow_from_directory(
    data_dir,
    target_size=(SIZE, SIZE),
    subset='validation'
)
```
이제 `ImageDataGenerator`에 몇 가지 정의사항을 입력해두었으니 이제 특정 디렉토리에서 데이터를 불러오기만 하면 됩니다. 이 같은 구조는 메모리를 효율적으로 다룰 수 있게 해줍니다. 이런 방식외에 데이터를 통째로 들고 학습하게 된다면 적은 양의 데이터셋에선 무사히 작동할 수 있으나, 대량의 데이터를 다루게 된다면 [Memory Allocation Error](https://stackoverflow.com/questions/60487683/why-am-i-getting-memory-allocation-error-even-on-batch-size-1)가 발생할 수 있습니다.<br>
`ImageDataGenerator`에 대해서는 다음 포스팅인 `Multi-class Classification`에서 자세히 다루도록 하겠습니다.
<br>

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers

num_classes = 1

model = Sequential()
model.add(layers.InputLayer(input_shape=(SIZE, SIZE, 3)))
model.add(layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Flatten())
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dense(num_classes, activation='sigmoid'))

model.summary()
```
인공신경망 모델 구성과 인공신경망의 `Layer`를 쌓기위한 라이브러리를 불러오고 분류할 클래스의 수를 정의합니다.<br>
강아지와 고양이를 분류하는 문제인데 `num_classes`에선 `1`로 설정한 이유는 이진 분류인 상황에서 `A`일 때 `1`, B일 때 `0`으로만 할당하면 이진 분류를 충분히 구현할 수 있기 때문입니다. 하지만 분류해야하는 가짓 수가 2가지가 넘어간다면 그 때부턴 분류해야하는 가짓 수에 맞춰 `num_classes`를 설정하면 됩니다.<br>
`model.summary()`를 통해서 우리가 쌓은 모델을 전체적으로 보기쉽게 확인할 수 있습니다.
<br>

```python
model.compile(
  optimizer='adam',
  loss='binary_crossentropy',
  metrics=['accuracy'])
```
구성한 모델에 적용할 `최적화함수`와 `손실함수` 그리고 `Metric`을 지정해줍니다. `손실함수`는 현재 이진 분류를 진행중이기 때문에 `binary_crossentropy`로 설정합니다.
<br>

```python
history = model.fit(
  X_train,
  epochs=EPOCHS,
  validation_data=X_valid
)
```
이제 `model.fit()`을 통해 학습을 진행합니다. `X_train`은 학습에 사용될 데이터입니다. `epochs`는 얼마나 반복할 지를 정하는 매개변수입니다. 우리는 이미 맨 처음 코드에서 `EPOCHS`라는 변수에 얼마나 반복할 지를 정해두었습니다. 그리고 마지막으로 `validation_data`가 있습니다. 학습을 진행하다보면 `과적합 (Overfitting)`에 빠질 수 있습니다. 이 때 검증 세트를 활용하여 학습하게 되면 모델은 편향된 학습방향에서 더 일반화된 결론으로 방향성을 가질 수 있습니다.

## 마무리
이번 포스팅에서는 간단하게 이진 분류를 구현해보았습니다. A 또는 B와 같은 이진 분류는 다양한 문제에 적용할 수 있으나 그 수가 제한적입니다. 다음 포스팅에서는 더욱 다양한 상황에 적용할 수 있는 다중 분류에 대해서 알아보겠습니다.
